{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\r\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\r\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry, Region\r\n",
    "from msrest.authentication import ApiKeyCredentials\r\n",
    "import os, time, uuid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Putting in key, endpoint and id values\r\n",
    "ENDPOINT = \"https://yoyoyo.cognitiveservices.azure.com/\"\r\n",
    "ENDPOINT2 = \"https://yoyoyo-prediction.cognitiveservices.azure.com/\"\r\n",
    "training_key = \"25cfe69107754f55ac33b305a527fe61\"\r\n",
    "prediction_key = \"e80894bfa56249c0b5238e2d5b936c70\"\r\n",
    "prediction_resource_id = \"/subscriptions/18ae480a-58ae-4be3-baa4-318cc8b683fb/resourceGroups/test-group/providers/Microsoft.CognitiveServices/accounts/yoyoyo-Prediction\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\r\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)\r\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\r\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT2, prediction_credentials)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "publish_iteration_name = \"detectModel\"\r\n",
    "\r\n",
    "# Finding the object detection domain\r\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() if domain.type == \"ObjectDetection\" and domain.name == \"General\")\r\n",
    "\r\n",
    "# Creating a new project\r\n",
    "print (\"Creating project NOW NOW NOW\")\r\n",
    "\r\n",
    "# Using uuid to avoid project name collisions.\r\n",
    "project = trainer.create_project(str(uuid.uuid4()), domain_id=obj_detection_domain.id)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Adding in the defect1 tag\r\n",
    "defect1_tag = trainer.create_tag(project.id, \"defect1\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "images = pd.read_csv('Train_DefectBoxes_PrithviAI.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "images.dropna(inplace=True)\r\n",
    "images.X = images.X - images.W/2\r\n",
    "images.Y = images.Y - images.H/2\r\n",
    "\r\n",
    "defect1_image_regions = images.set_index(\"  image_id\").T.to_dict('list')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "images.Y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "base_image_location = \"New_folder/Images_Unzipped/New_Images4\"\r\n",
    "\r\n",
    "# Going through the data above and creating the images\r\n",
    "print (\"Adding images\")\r\n",
    "tagged_images_with_regions = []\r\n",
    "\r\n",
    "for file_name in defect1_image_regions.keys():\r\n",
    "    x,y,w,h = defect1_image_regions[file_name]\r\n",
    "    regions = [Region(tag_id=defect1_tag.id, left=x,top=y,width=w,height=h) ]\r\n",
    "\r\n",
    "    try:\r\n",
    "        img_file = os.path.join(base_image_location, \"new_\" + file_name)\r\n",
    "        with open(img_file, mode=\"rb\") as image_contents:\r\n",
    "            tagged_images_with_regions.append(ImageFileCreateEntry(name=file_name, contents=image_contents.read(), regions=regions))\r\n",
    "    except:\r\n",
    "        pass\r\n",
    "\r\n",
    "print(tagged_images_with_regions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(tagged_images_with_regions))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "i = 0\r\n",
    "while i <= len(tagged_images_with_regions):\r\n",
    "    if i + 5 > len(tagged_images_with_regions):\r\n",
    "        tagged_images_with_regions_upload = tagged_images_with_regions[i:len(tagged_images_with_regions)]\r\n",
    "    else:\r\n",
    "        tagged_images_with_regions_upload = tagged_images_with_regions[i:i+5]\r\n",
    "    upload_result = trainer.create_images_from_files(project.id, ImageFileCreateBatch(images=tagged_images_with_regions_upload))\r\n",
    "    i += 5\r\n",
    "\r\n",
    "    if not upload_result.is_batch_successful:\r\n",
    "        print(\"Image batch upload failed.\")\r\n",
    "        for image in upload_result.images:\r\n",
    "            print(\"Image status: \", image.status)\r\n",
    "        exit(-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print (\"Training NOW\")\r\n",
    "iteration = trainer.train_project(project.id)\r\n",
    "while (iteration.status != \"Completed\"):\r\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\r\n",
    "    print(\"Training status: \" + iteration.status)\r\n",
    "    time.sleep(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The iteration is now trained. Publish it to the project endpoint\r\n",
    "trainer.publish_iteration(project.id, iteration.id, publish_iteration_name, prediction_resource_id)\r\n",
    "print (\"Finally, Done\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Now there is a trained endpoint that can be used to make a prediction\r\n",
    "ENDPOINT2 = \"https://yoyoyo-prediction.cognitiveservices.azure.com/\"\r\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT2, prediction_credentials)\r\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\r\n",
    "\r\n",
    "# Open the sample image and get back the prediction results.\r\n",
    "with open(os.path.join (\"test_image.png\"), mode=\"rb\") as test_data:\r\n",
    "    results = predictor.detect_image(project.id, publish_iteration_name, test_data)\r\n",
    "\r\n",
    "# Display the results.    \r\n",
    "for prediction in results.predictions:\r\n",
    "    print(\"\\t\" + prediction.tag_name + \": {0:.2f}% bbox.left = {1:.2f}, bbox.top = {2:.2f}, bbox.width = {3:.2f}, bbox.height = {4:.2f}\".format(prediction.probability * 100, prediction.bounding_box.left, prediction.bounding_box.top, prediction.bounding_box.width, prediction.bounding_box.height))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "776d0385c31ec595870eb83e4f9f34eaf6a8ac0041d0d5b8230ca7bfcf3c5fb0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}